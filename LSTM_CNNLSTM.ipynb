{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNCNt8uVob8D"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHOLA_MLwXWS",
        "outputId": "e2af810c-a059-4541-d0bf-cc045c2e4daa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "root = '/content/drive'\n",
        "drive.mount(root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6shfDtGZwlHl",
        "outputId": "71294c62-937d-47d9-8f16-1e2e1917fee0"
      },
      "outputs": [],
      "source": [
        "from os.path import join\n",
        "\n",
        "my_path = 'My Drive/Colab Notebooks/'\n",
        "project_path = join(root, my_path)\n",
        "print(project_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5Xo3juxxo9E",
        "outputId": "1b8dec1c-e212-4d09-c12f-df8f80ba3014"
      },
      "outputs": [],
      "source": [
        "%cd '{project_path}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 878
        },
        "id": "cm_whDD06ynr",
        "outputId": "537273b7-666d-4a6b-9df6-04e95cc10943"
      },
      "outputs": [],
      "source": [
        "for i in os.listdir(project_path+'modeling_dataset/'):\n",
        "    df = pd.read_csv(project_path+'modeling_dataset/'+i)\n",
        "    \n",
        "# 날짜에 따른 변수들의 변화 시각화\n",
        "    plt.figure(figsize=(35, 15))\n",
        "    name = i.split('.')[0]\n",
        "\n",
        "    plt.subplot(321)\n",
        "    plt.plot(df['date'], df['social_buzz'],label='social_buzz')\n",
        "    plt.title('<'+name+'>' 'Social buzz')\n",
        "\n",
        "    plt.subplot(322)\n",
        "    plt.plot(df['date'], df['minimum temperature(°C)'],label='minimum temperature(°C)')\n",
        "    plt.title('Minimum temperature(°C)')\n",
        "\n",
        "    plt.subplot(323)\n",
        "    plt.plot(df['date'], df['maximum temperature(°C)'],label='maximum temperature(°C)')\n",
        "    plt.title('Maximum temperature(°C)')\n",
        "\n",
        "    plt.subplot(324)\n",
        "    plt.plot(df['date'], df['humidity(%)'],label='humidity(%)')\n",
        "    plt.title('Humidity(%)')\n",
        "\n",
        "    plt.subplot(325)\n",
        "    plt.plot(df['date'], df['precip_prob(%)'],label='precip_prob(%)')\n",
        "    plt.title('Precip_ probability(%)')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyunOg_Lv35z"
      },
      "outputs": [],
      "source": [
        "# GPU 설정하기\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pap6uSGZv350"
      },
      "outputs": [],
      "source": [
        "# LSTM 네트워크 구성하기\n",
        "class LSTM1(nn.Module):\n",
        "  def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "    super(LSTM1, self).__init__()\n",
        "    # 클래스 개수\n",
        "    self.num_classes = num_classes \n",
        "    #layer 개수\n",
        "    self.num_layers = num_layers \n",
        "    #input 사이즈\n",
        "    self.input_size = input_size \n",
        "    #hidden state\n",
        "    self.hidden_size = hidden_size \n",
        "    #sequence 길이\n",
        "    self.seq_length = seq_length \n",
        "\n",
        "    #LSTM\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                      num_layers=num_layers, batch_first=True) \n",
        "    # fully connected \n",
        "    self.fc_1 =  nn.Linear(hidden_size, 128) \n",
        "    # fully connected 마지막 layer\n",
        "    self.fc = nn.Linear(128, num_classes) \n",
        "    # activation function : ReLU\n",
        "    self.relu = nn.ReLU() \n",
        "\n",
        "  # Forward propagate \n",
        "  def forward(self,x):\n",
        "    # hidden state\n",
        "    h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device) \n",
        "    # internal state\n",
        "    c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).to(device)   \n",
        "\n",
        "    output, (hn, cn) = self.lstm(x, (h_0, c_0)) \n",
        "   \n",
        "    # lstm에 맞게 data shape 변경\n",
        "    hn = hn.view(-1, self.hidden_size) \n",
        "    out = self.relu(hn)\n",
        "    # 첫번째 Dense\n",
        "    out = self.fc_1(out)\n",
        "    out = self.relu(out)\n",
        "    # 최종 output\n",
        "    out = self.fc(out) \n",
        "   \n",
        "    return out "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGoelLtlv351"
      },
      "outputs": [],
      "source": [
        "# CNN LSTM 네트워크 구성하기\n",
        "class CNN_LSTM(nn.Module):\n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
        "        super(CNN_LSTM, self).__init__()\n",
        "        # CNN 1D layer \n",
        "        self.conv1d_1 = nn.Conv1d(in_channels=input_size,\n",
        "                                out_channels=16,\n",
        "                                kernel_size=3,\n",
        "                                stride=1,\n",
        "                                padding=1)\n",
        "        self.conv1d_2 = nn.Conv1d(in_channels=16,\n",
        "                                out_channels=32,\n",
        "                                kernel_size=3,\n",
        "                                stride=1,\n",
        "                                padding=1)\n",
        "        \n",
        "        # LSTM\n",
        "        self.lstm = nn.LSTM(input_size=32,\n",
        "                            hidden_size=64,\n",
        "                            num_layers=1,\n",
        "                            bias=True,\n",
        "                            bidirectional=False,\n",
        "                            batch_first=True)\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "        self.dense1 = nn.Linear(64, 32)\n",
        "        self.dense2 = nn.Linear(32, 16)\n",
        "\n",
        "        # fully connected layer 1\n",
        "        self.fc_layer1 = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            # activation function : LeakyReLU\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.1)\n",
        "        )\n",
        "        # fully connected layer 2\n",
        "        self.fc_layer2 = nn.Sequential(\n",
        "            nn.Linear(32, 1),\n",
        "            # activation function : LeakyReLU\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Dropout(p = 0.1)\n",
        "        )\n",
        "\n",
        "    # Forward propagate \n",
        "    def forward(self, x):\n",
        "  \t# Raw x shape : (B, S, F) -> (B, 10, 3)\n",
        "        \n",
        "        # Shape : (B, F, S) -> (B, 3, 10)\n",
        "        x = x.transpose(1, 2)\n",
        "        # Shape : (B, F, S) == (B, C, S) // C = channel -> (B, 16, 10)\n",
        "        x = self.conv1d_1(x)\n",
        "        # Shape : (B, C, S) -> (B, 32, 10)\n",
        "        x = self.conv1d_2(x)\n",
        "        # Shape : (B, S, C) == (B, S, F) -> (B, 10, 32)\n",
        "        x = x.transpose(1, 2)\n",
        "        \n",
        "        self.lstm.flatten_parameters()\n",
        "        # Shape : (B, S, H) // H = hidden_size -> (B, 10, 50)\n",
        "        _, (hidden, _) = self.lstm(x)\n",
        "        # Shape : (B, H) // -1 means the last sequence -> (B, 50)\n",
        "        x = hidden[-1]\n",
        "        # Shape : (B, H) -> (B, 50)\n",
        "        x = self.dropout(x)\n",
        "        \n",
        "        # Shape : (B, 32)\n",
        "        x = self.fc_layer1(x)\n",
        "        # 최종 output\n",
        "        x = self.fc_layer2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mv8CLVPSv354"
      },
      "outputs": [],
      "source": [
        "# MSE 값 넣기 위해 리스트 생성\n",
        "lstm_temp = []\n",
        "cnn_temp = []\n",
        "rmse = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "N-mPlUSxmeNg",
        "outputId": "f48b98ec-e91d-4625-8cb0-30255b0488fa"
      },
      "outputs": [],
      "source": [
        "# feature별로 범위가 달라 scaler 사용\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "\n",
        "for i in os.listdir('./modeling_dataset/'):\n",
        "    # 데이터셋 준비하기\n",
        "    df = pd.read_csv('./modeling_dataset/'+i)\n",
        "    df = df.drop('poi', axis = 1)\n",
        "    df.index = df['date']\n",
        "    df = df.drop('date', axis = 1)\n",
        "    X = df.drop(columns='num_of_search')\n",
        "    y = df.iloc[:,8:9]\n",
        "\n",
        "    mm = MinMaxScaler()\n",
        "    ss = StandardScaler()\n",
        "\n",
        "    X_ss = ss.fit_transform(X)\n",
        "    y_mm = mm.fit_transform(y)\n",
        "\n",
        "    # Train, Test 데이터셋 분리하기\n",
        "    X_train = X_ss[:304,:]\n",
        "    X_test = X_ss[304:,:]\n",
        "\n",
        "    y_train = y_mm[:304,:]\n",
        "    y_test = y_mm[304:,:]\n",
        "\n",
        "    # 학습할 수 있는 tensor형태로 변환\n",
        "    X_train_tensors = Variable(torch.Tensor(X_train))\n",
        "    X_test_tensors = Variable(torch.Tensor(X_test))\n",
        "\n",
        "    y_train_tensors = Variable(torch.Tensor(y_train))\n",
        "    y_test_tensors = Variable(torch.Tensor(y_test))\n",
        "\n",
        "    X_train_tensors_final = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], 1, X_train_tensors.shape[1]))\n",
        "    X_test_tensors_final = torch.reshape(X_test_tensors,  (X_test_tensors.shape[0], 1, X_test_tensors.shape[1])) \n",
        "\n",
        "    # model1 - LSTM\n",
        "    # 네트워크 파라미터 구성하기\n",
        "    num_epochs = 10000\n",
        "    learning_rate = 0.005 \n",
        "\n",
        "    # feature 개수\n",
        "    input_size = 8 \n",
        "    # hidden state의 feature 개수\n",
        "    hidden_size = 4 \n",
        "    # lstm layer 개수\n",
        "    num_layers = 1 \n",
        "\n",
        "    # output class 개수\n",
        "    num_classes = 1 \n",
        "\n",
        "    # 모델 구현\n",
        "    lstm1 = LSTM1(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]).to(device)\n",
        "\n",
        "    # Mean-squared error for regression\n",
        "    loss_function = torch.nn.MSELoss()   \n",
        "    # Adam optimizer \n",
        "    optimizer = torch.optim.Adam(lstm1.parameters(), lr=learning_rate)  \n",
        "\n",
        "    # 학습하기\n",
        "    lstm1.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        # forward pass\n",
        "        outputs = lstm1.forward(X_train_tensors_final.to(device)) \n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # loss function\n",
        "        loss = loss_function(outputs, y_train_tensors.to(device))\n",
        "\n",
        "        # loss function의 loss 계산\n",
        "        loss.backward() \n",
        "        \n",
        "        optimizer.step() \n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) \n",
        "\n",
        "    # 예측 할 수 있는 tensor형태로 변환\n",
        "    X_test2 = Variable(torch.Tensor(X_test)) #converting to Tensors\n",
        "    y_test2 = Variable(torch.Tensor(y_test))\n",
        "\n",
        "    X_test2 = torch.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
        "    lstm1.eval()\n",
        "    # forward pass\n",
        "    train_predict = lstm1(X_test2.to(device))\n",
        "    data_predict = train_predict.data.detach().cpu().numpy() \n",
        "    dataY_plot = y_test2.data.numpy()\n",
        "\n",
        "    # 결과 시각화\n",
        "    data_predict_to_plot =  [i[0] for i in data_predict]\n",
        "    dataY_plot_to_plot =  [i[0] for i in dataY_plot]\n",
        "    plt.figure(figsize=(10,6)) \n",
        "    plt.plot(dataY_plot, label='Actual num_tourist') \n",
        "    plt.plot(data_predict, label='Predicted num_tourist') \n",
        "    name = i.split('.')[0]\n",
        "    plt.title(name+ '(LSTM)')\n",
        "    plt.legend()\n",
        "    plt.savefig('./'+name+'_lstm')\n",
        "    plt.show()\n",
        "\n",
        "    lstm_temp.append(math.sqrt(loss))\n",
        "    print(\"RMSE: %s\" % math.sqrt(loss))\n",
        "\n",
        "\n",
        "\n",
        "    # model2 - CNN LSTM\n",
        "    # 네트워크 파라미터 구성하기\n",
        "    num_epochs = 4000\n",
        "    learning_rate = 0.005\n",
        "\n",
        "    # feature 개수\n",
        "    input_size = 8 \n",
        "    # hidden state의 feature 개수\n",
        "    hidden_size = 4 \n",
        "    # lstm layer 개수\n",
        "    num_layers = 1 \n",
        "\n",
        "    num_classes = 1 #number of output classes \n",
        "\n",
        "    cnn_lstm = CNN_LSTM(num_classes, input_size, hidden_size, num_layers, X_train_tensors_final.shape[1]).to(device)\n",
        "\n",
        "    # Mean-squared error for regression\n",
        "    loss_function = torch.nn.MSELoss()    \n",
        "    # Adam optimizer\n",
        "    optimizer = torch.optim.Adam(cnn_lstm.parameters(), lr=learning_rate) \n",
        "\n",
        "    # 학습하기\n",
        "    cnn_lstm.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        #forward pass\n",
        "        outputs = cnn_lstm.forward(X_train_tensors_final.to(device)) \n",
        "        optimizer.zero_grad() \n",
        "        \n",
        "        # loss function\n",
        "        loss = loss_function(outputs, y_train_tensors.to(device))\n",
        "\n",
        "        # loss function의 loss 계산\n",
        "        loss.backward() \n",
        "        \n",
        "        optimizer.step() \n",
        "        if epoch % 100 == 0:\n",
        "            print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item())) \n",
        "\n",
        "    # 예측할 수 있는 tensor형태로 변환\n",
        "    X_test2 = Variable(torch.Tensor(X_test)) \n",
        "    y_test2 = Variable(torch.Tensor(y_test))\n",
        "\n",
        "    X_test2 = torch.reshape(X_test2, (X_test2.shape[0], 1, X_test2.shape[1]))\n",
        "    cnn_lstm.eval()\n",
        "    # forward pass\n",
        "    train_predict = cnn_lstm(X_test2.to(device))\n",
        "    data_predict = train_predict.data.detach().cpu().numpy() \n",
        "    dataY_plot = y_test2.data.numpy()\n",
        "\n",
        "    # 결과 시각화\n",
        "    data_predict_to_plot =  [i[0] for i in data_predict]\n",
        "    dataY_plot_to_plot =  [i[0] for i in dataY_plot]\n",
        "\n",
        "    plt.figure(figsize=(10,6)) \n",
        "    plt.plot(dataY_plot, label='Actual num_tourist') \n",
        "    plt.plot(data_predict, label='Predicted num_tourist') \n",
        "    plt.title(name+ '(CNN LSTM)')\n",
        "    plt.legend()\n",
        "    plt.savefig('./'+name+'_cnn')\n",
        "    plt.show() \n",
        "\n",
        "    # MSE -> RMSE 바꾸기 위해 제곱근 계산\n",
        "    cnn_temp.append(math.sqrt(loss))\n",
        "    print(\"RMSE: %s\" % math.sqrt(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97wsw385v357"
      },
      "outputs": [],
      "source": [
        "# RMSE score, 모델 별 RMSE 평균 데이터프레임 생성\n",
        "rmse['LSTM'] = pd.DataFrame(lstm_temp)\n",
        "rmse['CNN_LSTM'] = pd.DataFrame(cnn_temp)\n",
        "rmse = rmse.append({'LSTM' : np.mean(lstm_temp), 'CNN_LSTM' : np.mean(cnn_temp)}, ignore_index=True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM_CNNLSTM.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 ('MTWT')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "c007ce45ef9d90ec81e14d1d236b8c9676631cbb335d0d87b764845e6e455b30"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
